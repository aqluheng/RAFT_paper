{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e846f9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('core')\n",
    "import argparse\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e016df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7004fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_to_align(x, align):\n",
    "    \"\"\"Pad image batch x so width and height divide by align.\n",
    "\n",
    "    Args:\n",
    "      x: Image batch to align.\n",
    "      align: Number to align to.\n",
    "\n",
    "    Returns:\n",
    "      1) An image padded so width % align == 0 and height % align == 0.\n",
    "      2) A bounding box that can be fed readily to tf.image.crop_to_bounding_box\n",
    "        to undo the padding.\n",
    "    \"\"\"\n",
    "    # Input checking.\n",
    "    assert np.ndim(x) == 4\n",
    "    assert align > 0, \"align must be a positive number.\"\n",
    "\n",
    "    height, width = x.shape[-3:-1]\n",
    "    height_to_pad = (align - height % align) if height % align != 0 else 0\n",
    "    width_to_pad = (align - width % align) if width % align != 0 else 0\n",
    "\n",
    "    bbox_to_pad = {\n",
    "        \"offset_height\": height_to_pad // 2,\n",
    "        \"offset_width\": width_to_pad // 2,\n",
    "        \"target_height\": height + height_to_pad,\n",
    "        \"target_width\": width + width_to_pad,\n",
    "    }\n",
    "    #  print(bbox_to_pad)\n",
    "    padded_x = tf.image.pad_to_bounding_box(x, **bbox_to_pad)\n",
    "    bbox_to_crop = {\n",
    "        \"offset_height\": height_to_pad // 2,\n",
    "        \"offset_width\": width_to_pad // 2,\n",
    "        \"target_height\": height,\n",
    "        \"target_width\": width,\n",
    "    }\n",
    "    return padded_x, bbox_to_crop\n",
    "\n",
    "\n",
    "def flow_to_color(flow, mask=None, max_flow=None):\n",
    "    \"\"\"Converts flow to 3-channel color image.\n",
    "\n",
    "    Args:\n",
    "        flow: tensor of shape [num_batch, height, width, 2].\n",
    "        mask: flow validity mask of shape [num_batch, height, width, 1].\n",
    "        max_flow: unused argument.\n",
    "\n",
    "    Returns:\n",
    "      flow in 3-channel RGB image.\n",
    "\n",
    "    Snippet Reference:\n",
    "      Code: https://github.com/ppliuboy/SelFlow/blob/master/flowlib.py#L109\n",
    "      MIT License: https://github.com/ppliuboy/SelFlow/blob/master/LICENSE\n",
    "    \"\"\"\n",
    "    n = 8\n",
    "    height, width, _ = tf.unstack(tf.shape(flow))\n",
    "    mask = tf.ones([height, width, 1]) if mask is None else mask\n",
    "    flow_u, flow_v = tf.unstack(flow, axis=2)\n",
    "    if max_flow is not None:\n",
    "        max_flow = tf.maximum(tf.to_float(max_flow), 1.0)\n",
    "    else:\n",
    "        max_flow = tf.reduce_max(tf.abs(flow * mask))\n",
    "    mag = tf.sqrt(tf.reduce_sum(tf.square(flow), 2))\n",
    "    angle = tf.atan2(flow_v, flow_u)\n",
    "\n",
    "    im_h = tf.math.mod(angle / (2 * np.pi) + 1.0, 1.0)\n",
    "    im_s = tf.clip_by_value(mag * n / max_flow, 0, 1)\n",
    "    im_v = tf.clip_by_value(n - im_s, 0, 1)\n",
    "    im_hsv = tf.stack([im_h, im_s, im_v], 2)\n",
    "    im = tf.image.hsv_to_rgb(im_hsv)\n",
    "    return im * mask\n",
    "\n",
    "\n",
    "def flow_to_img(flow, normalize=True, info=None, flow_mag_max=None):\n",
    "    \"\"\"Convert flow to viewable image, using color hue to encode flow vector orientation, and color saturation to\n",
    "\n",
    "    encode vector length. This is similar to the OpenCV tutorial on dense\n",
    "    optical flow, except that they map vector\n",
    "    length to the value plane of the HSV color model, instead of the saturation\n",
    "    plane, as we do here.\n",
    "    Args:\n",
    "        flow: optical flow\n",
    "        normalize: Normalize flow to 0..255\n",
    "        info: Text to superimpose on image (typically, the epe for the predicted\n",
    "          flow)\n",
    "        flow_mag_max: Max flow to map to 255\n",
    "\n",
    "    Returns:\n",
    "        img: viewable representation of the dense optical flow in RGB format\n",
    "        flow_avg: optionally, also return average flow magnitude\n",
    "    Ref:\n",
    "        - OpenCV 3.0.0-dev documentation » OpenCV-Python Tutorials » Video\n",
    "        Analysis »\n",
    "        https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_video/py_lucas_kanade/py_lucas_kanade.html\n",
    "        https://github.com/philferriere/tfoptflow/blob/master/tfoptflow/optflow.py#L190\n",
    "        https://github.com/philferriere/tfoptflow/blob/master/LICENSE\n",
    "    \"\"\"\n",
    "    hsv = np.zeros((flow.shape[0], flow.shape[1], 3), dtype=np.uint8)\n",
    "    flow_magnitude, flow_angle = cv2.cartToPolar(\n",
    "        flow[..., 0].astype(np.float32), flow[..., 1].astype(np.float32)\n",
    "    )\n",
    "\n",
    "    # A couple times, we've gotten NaNs out of the above...\n",
    "    nans = np.isnan(flow_magnitude)\n",
    "    if np.any(nans):\n",
    "        nans = np.where(nans)\n",
    "        flow_magnitude[nans] = 0.0\n",
    "\n",
    "    # Normalize\n",
    "    hsv[..., 0] = flow_angle * 180 / np.pi / 2\n",
    "    if normalize is True:\n",
    "        if flow_mag_max is None:\n",
    "            hsv[..., 1] = cv2.normalize(flow_magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        else:\n",
    "            hsv[..., 1] = flow_magnitude * 255 / flow_mag_max\n",
    "    else:\n",
    "        hsv[..., 1] = flow_magnitude\n",
    "    hsv[..., 2] = 255\n",
    "    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    # Add text to the image, if requested\n",
    "    if info is not None:\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img, info, (20, 20), font, 0.8, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed0b196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_optical_flow_raft(loaded_model, image0, image1):\n",
    "    image0 = tf.cast(image0, tf.float32) / 128.5 - 1\n",
    "    image1 = tf.cast(image1, tf.float32) / 128.5 - 1\n",
    "\n",
    "    image0_batch = np.reshape(image0, (1,) + image0.shape)\n",
    "    image1_batch = np.reshape(image1, (1,) + image1.shape)\n",
    "    image0_batch = tf.convert_to_tensor(image0_batch, dtype=tf.float32)\n",
    "    image1_batch = tf.convert_to_tensor(image1_batch, dtype=tf.float32)\n",
    "\n",
    "    image0_batch, bbox_to_crop = _pad_to_align(image0_batch, align=64)\n",
    "    image1_batch, bbox_to_crop = _pad_to_align(image1_batch, align=64)\n",
    "\n",
    "    input_batch = tf.concat([image0_batch, image1_batch], axis=0)\n",
    "    input_batch = tf.expand_dims(input_batch, axis=0)\n",
    "\n",
    "    flow_output = loaded_model(input_1=input_batch, input_2=tf.constant(12))\n",
    "\n",
    "    flow_output = tf.image.crop_to_bounding_box(flow_output[\"output_1\"], **bbox_to_crop)\n",
    "\n",
    "    height, width, _ = image0.shape\n",
    "    flow_shape = flow_output.shape\n",
    "    np.testing.assert_array_equal(flow_shape, (1,) + (height, width, 2))\n",
    "\n",
    "    return flow_output.numpy()[0]\n",
    "\n",
    "\n",
    "def run_raft_it(model, im0_path, im1_path):\n",
    "    im0 = media.read_image(im0_path)\n",
    "    im1 = media.read_image(im1_path)\n",
    "    optflow = calculate_optical_flow_raft(model.signatures[\"serving_default\"], im0, im1)\n",
    "    media.show_images([im0, im1, flow_to_img(optflow)])\n",
    "    return optflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927314c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for dstype in ['final']:\n",
    "    val_dataset = datasets.MpiSintel(split='training', dstype=dstype)\n",
    "    epe_list = []\n",
    "\n",
    "    for val_id in range(len(val_dataset)):\n",
    "        images, flow_gt, _ = val_dataset[val_id]\n",
    "        image0, image1 = images[0], images[1]\n",
    "\n",
    "        flow_low, flow_pr = model(images, iters=iters, test_mode=True)\n",
    "        flow = padder.unpad(flow_pr[0]).cpu()\n",
    "\n",
    "        epe = torch.sum((flow - flow_gt)**2, dim=0).sqrt()\n",
    "        epe_list.append(epe.view(-1).numpy())\n",
    "\n",
    "    epe_all = np.concatenate(epe_list)\n",
    "    epe = np.mean(epe_all)\n",
    "    px1 = np.mean(epe_all<1)\n",
    "    px3 = np.mean(epe_all<3)\n",
    "    px5 = np.mean(epe_all<5)\n",
    "\n",
    "    print(\"Validation sintel (%s) EPE: %f, 1px: %f, 3px: %f, 5px: %f, >3px: %f\" % (dstype, epe, px1, px3, px5, (1-px3)*100))\n",
    "    results[dstype] = np.mean(epe_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ad8b55a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dstype' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4ca91e029b2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raft_it_ft\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallow_partial_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMpiSintel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdstype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdstype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moptflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_optical_flow_raft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'serving_default'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dstype' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.compat.v2.saved_model.load(\"raft_it_ft\", options=tf.saved_model.LoadOptions(allow_partial_checkpoint=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ef9c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for dstype in ['final']:\n",
    "    val_dataset = datasets.MpiSintel(split='training', dstype=dstype)\n",
    "    epe_list = []\n",
    "\n",
    "    for val_id in range(len(val_dataset)):\n",
    "        images, flow_gt, _ = val_dataset[val_id]\n",
    "        image0, image1 = images[0], images[1]\n",
    "        \n",
    "        \n",
    "\n",
    "        epe = torch.sum((flow - flow_gt)**2, dim=0).sqrt()\n",
    "        epe_list.append(epe.view(-1).numpy())\n",
    "\n",
    "    epe_all = np.concatenate(epe_list)\n",
    "    epe = np.mean(epe_all)\n",
    "    px1 = np.mean(epe_all<1)\n",
    "    px3 = np.mean(epe_all<3)\n",
    "    px5 = np.mean(epe_all<5)\n",
    "\n",
    "    print(\"Validation sintel (%s) EPE: %f, 1px: %f, 3px: %f, 5px: %f, >3px: %f\" % (dstype, epe, px1, px3, px5, (1-px3)*100))\n",
    "    results[dstype] = np.mean(epe_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ce3ceee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ce52ffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapy as media\n",
    "val_dataset = datasets.MpiSintel(split='training', dstype=\"final\")\n",
    "\n",
    "images, flow_gt, _ = val_dataset[0]\n",
    "images = images.permute(0,2,3,1)\n",
    "im0, im1 = images[0], images[1]\n",
    "optflow = calculate_optical_flow_raft(model.signatures['serving_default'], im0, im1)\n",
    "# media.show_images([np.uint8(im0), np.uint8(im1), flow_to_img(optflow), flow_to_img(np.array(flow_gt).transpose((2,0,1)))])\n",
    "# media.show_images([np.uint8(im0), flow_to_img(optflow), flow_to_img(np.array(flow_gt).transpose((1,2,0)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "499fff06",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-58dd5ffcdb8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mflow_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow_gt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mepe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mflow_gt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'flow' is not defined"
     ]
    }
   ],
   "source": [
    "flow = np.array(optflow).transpose((2,0,1))\n",
    "flow_gt = np.array(flow_gt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "01387f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "epe = np.sqrt(np.sum((optflow*16 - flow_gt)**2, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "38a20227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5081654"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epe.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
